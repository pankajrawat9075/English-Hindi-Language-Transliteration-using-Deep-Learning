{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pankajrawat9075/CS6910_assignment_3/blob/main/DL_PA3_final_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRdpoWePeYHn"
      },
      "source": [
        "## Importing Libraries and models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LBvFtYGCNgJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkZTzr7OCPBM"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4ZVrIumZcDt"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwL09v65CIse",
        "outputId": "d052965d-82db-4891-9b22-13c0cfbb4a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44xIRolL_T_d"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XRMpx9eBzRK",
        "outputId": "50f57a43-1b9b-47d2-b4a2-af5f78e8ae92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j2WAfsh_TZU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4zemXiyE6Fi"
      },
      "outputs": [],
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.char2index = {'#': 0, '$': 1, '^': 2}\n",
        "        self.char2count = {'#': 1, '$': 1, '^': 1}\n",
        "        self.index2char = {0: '#', 1: '$', 2: '^'}\n",
        "        self.n_chars = 3  # Count\n",
        "        self.data = {}\n",
        "        \n",
        "\n",
        "    def addWord(self, word):\n",
        "        for char in word:\n",
        "            self.addChar(char)\n",
        "\n",
        "    def addChar(self, char):\n",
        "        if char not in self.char2index:\n",
        "            self.char2index[char] = self.n_chars\n",
        "            self.char2count[char] = 1\n",
        "            self.index2char[self.n_chars] = char\n",
        "            self.n_chars += 1\n",
        "        else:\n",
        "            self.char2count[char] += 1\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCR658yRvXpy"
      },
      "outputs": [],
      "source": [
        "# return max length of input and output words\n",
        "def maxLength(data):\n",
        "    ip_mlen, op_mlen = 0, 0\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        input = data[0][i]\n",
        "        output = data[1][i]\n",
        "        if(len(input)>ip_mlen):\n",
        "            ip_mlen=len(input)\n",
        "\n",
        "        if(len(output)>op_mlen):\n",
        "            op_mlen=len(output)\n",
        "\n",
        "    return ip_mlen, op_mlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDGaCO8DkYpc"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "input_shape = 0\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "def preprocess(data, input_lang, output_lang):\n",
        "    maxlenInput, maxlenOutput = maxLength(data)\n",
        "    # we use maxlenInput as 26 since it is the maximum of all input len\n",
        "    maxlenInput = 26\n",
        "    input = numpy.zeros((len(data), maxlenInput + 1))\n",
        "    output = numpy.zeros((len(data), maxlenOutput + 2))\n",
        "    maxlenInput, maxlenOutput = maxLength(data)\n",
        "    unknown = input_lang.char2index['$']\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        op = '^' + data[1][i]\n",
        "        ip = data[0][i].ljust(maxlenInput + 1, '#')\n",
        "        op = op.ljust(maxlenOutput + 2, '#')\n",
        "        \n",
        "\n",
        "        for index, char in enumerate(ip):\n",
        "            if input_lang.char2index.get(char) is not None:\n",
        "                input[i][index] = input_lang.char2index[char]\n",
        "            else:\n",
        "                input[i][index] = unknown\n",
        "        \n",
        "\n",
        "        \n",
        "        for index, char in enumerate(op):\n",
        "            if output_lang.char2index.get(char) is not None:\n",
        "                output[i][index] = output_lang.char2index[char]\n",
        "            else:\n",
        "                output[i][index] = unknown  \n",
        "\n",
        "    print(input.shape)\n",
        "    print(output.shape)\n",
        "\n",
        "    return TensorDataset(torch.from_numpy(input), torch.from_numpy(output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdS5OXKxfdCX",
        "outputId": "87d2622f-6cf9-4e3d-b499-4aef38d8e0e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(51200, 27)\n",
            "(51200, 22)\n",
            "(4096, 27)\n",
            "(4096, 22)\n",
            "(4096, 27)\n",
            "(4096, 22)\n"
          ]
        }
      ],
      "source": [
        "def loadData(lang):\n",
        "    train_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_train.csv\", header = None)\n",
        "    val_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_valid.csv\", header = None)\n",
        "    test_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_test.csv\", header = None)\n",
        "\n",
        "    input_lang = Lang('eng')\n",
        "    output_lang = Lang(lang)\n",
        "    \n",
        "    # add the words to the respective languages\n",
        "    for i in range(len(train_df)):\n",
        "        \n",
        "        input_lang.addWord(train_df[0][i])\n",
        "        output_lang.addWord(train_df[1][i])\n",
        "\n",
        "    # print(input_lang.char2index)\n",
        "    # print(input_lang.index2char)\n",
        "    trainDataset = preprocess(train_df, input_lang, output_lang)\n",
        "    testDataset = preprocess(test_df, input_lang, output_lang)\n",
        "    valDataset = preprocess(val_df, input_lang, output_lang)\n",
        "\n",
        "    return trainDataset, testDataset, valDataset, input_lang, output_lang\n",
        "\n",
        "\n",
        "trainData, testData, valData, ipLang, opLang = loadData('hin')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key =\"c891ce08bb56081ecfa97de464a131634657ac13\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvmzS5Lt_Jnl",
        "outputId": "5735810e-9733-407f-ee58-faeca8654778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7qnG1gZL_HHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1TioafYgICa"
      },
      "source": [
        "# seq2seq model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svxssm9Havhb"
      },
      "source": [
        "## Encoder(contains the embedding layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTwk8nKNcbkb"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, embedding_size, # input_size is size of input language dictionary\n",
        "                 num_layers, cell_type,\n",
        "                  bidirectional, dropout, batch_size) :\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size  # size of an hidden state representation\n",
        "        self.num_layers = num_layers   \n",
        "        self.bidirectional = True if bidirectional == 'Yes' else False\n",
        "        self.batch_size = batch_size\n",
        "        self.cell_type = cell_type\n",
        "        self.embedding_size=embedding_size\n",
        "\n",
        "        # this adds the embedding layer\n",
        "        self.embedding = nn.Embedding(num_embeddings=input_size,embedding_dim= embedding_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # this adds the Neural Network layer for the encoder\n",
        "        if self.cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
        "        elif self.cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
        "\n",
        "    def forward(self, input, hidden): # input shape (seq_len, batch_size) hidden shape tuple for lstm, otherwise single\n",
        "        embedded = self.embedding(input.long()).view(-1,self.batch_size, self.embedding_size)\n",
        "        output = self.dropout(embedded) # output shape (seq_len, batch_size, embedding size)\n",
        "\n",
        "        output, hidden = self.rnn(output, hidden) # for LSTM hidden is a tuple\n",
        "        if self.bidirectional:\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                hidden_state = hidden[0].resize(2,self.num_layers,self.batch_size,self.hidden_size)\n",
        "                cell_state = hidden[1].resize(2,self.num_layers,self.batch_size,self.hidden_size)\n",
        "                hidden = (torch.add(hidden_state[0],hidden_state[1])/2, torch.add(cell_state[0],cell_state[1])/2)\n",
        "            else:\n",
        "                hidden=hidden.resize(2,self.num_layers,self.batch_size,self.hidden_size)\n",
        "                hidden=torch.add(hidden[0],hidden[1])/2\n",
        "            \n",
        "            split_tensor= torch.split(output, self.hidden_size, dim=-1)\n",
        "            output=torch.add(split_tensor[0],split_tensor[1])/2\n",
        "        return output, hidden\n",
        "\n",
        "    # initializing the initial hidden state for the encoder\n",
        "    def initHidden(self):\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            return (torch.zeros(self.num_layers * num_directions, self.batch_size, self.hidden_size, device=device),\n",
        "                    torch.zeros(self.num_layers * num_directions, self.batch_size, self.hidden_size, device=device))\n",
        "        else:\n",
        "            return torch.zeros(self.num_layers * num_directions, self.batch_size, self.hidden_size, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J56aq1J6a07q"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53ki6eJUH2u2"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, embedding_size, num_layers, # output size is the size of output language dictionary\n",
        "                 cell_type, dropout, batch_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_size=embedding_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        if self.cell_type == \"gru\":\n",
        "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_layers)\n",
        "        elif self.cell_type == \"lstm\":\n",
        "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_layers)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_layers)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, input, hidden): # input shape (1, batch_size)\n",
        "        embedded = self.embedding(input.long()).view(-1, self.batch_size, self.embedding_size)\n",
        "        # # shape (1, batch_size, embedding_size)\n",
        "        output = F.relu(embedded)\n",
        "        output, hidden = self.rnn(output, hidden) # output shape (1, batch_size, hidden_size)\n",
        "        output = self.softmax(self.out(output)) # shape (1, batch_size, output_size)\n",
        "        return output, hidden\n",
        "\n",
        "    # not needed since hidden will be provided by the encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Decoder"
      ],
      "metadata": {
        "id": "5JcQdylzI_Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, embedding_size, num_layers,\n",
        "                 cell_type, dropout, batch_size, max_length):\n",
        "        super(AttentionDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.cell_type = cell_type\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.max_length = max_length\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        self.dropout = nn.Dropout(self.dropout)\n",
        "        self.attention = nn.Linear(hidden_size + embedding_size, self.max_length)\n",
        "        self.attention_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
        "\n",
        "        if self.cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers=num_layers)\n",
        "        elif self.cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(hidden_size, hidden_size, num_layers=num_layers)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs): #input shape (1, batch_size)\n",
        "        embedded = self.embedding(input.long()).view(-1, self.batch_size, self.embedding_size) \n",
        "        # embedded shape (1, batch_size, embedding_size)\n",
        "        embedded = F.relu(embedded)\n",
        "\n",
        "        # Compute attention scores\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            attn_hidden = torch.mean(hidden[0], dim=0)\n",
        "        else:\n",
        "            attn_hidden = torch.mean(hidden, dim = 0)\n",
        "        attn_scores = self.attention(torch.cat((embedded, attn_hidden.unsqueeze(0)), dim=2)) # attn_scores shape (1, batch_size, max_length)\n",
        "        \n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)  # attn_scores shape (1, 16, 25)\n",
        "        \n",
        "\n",
        "        # Apply attention weights to encoder outputs\n",
        "        attn_applied = torch.bmm(attn_weights.transpose(0, 1), encoder_outputs.transpose(0, 1))\n",
        "        \n",
        "        # Combine attention output and embedded input\n",
        "        combined = torch.cat((embedded, attn_applied.transpose(0, 1)), dim=2)\n",
        "        combined = self.attention_combine(combined)\n",
        "        combined = F.relu(combined) # shape (1, batch_size, hidden_size)\n",
        "\n",
        "        # Run through the RNN\n",
        "        output, hidden = self.rnn(combined, hidden)\n",
        "        # output shape: (1, batch_size, hidden_size)\n",
        "\n",
        "        # Pass through linear layer and softmax activation\n",
        "        output = self.out(output)  # shape: (1, batch_size, output_size)\n",
        "        output = self.softmax(output)\n",
        "\n",
        "        return output, hidden, attn_weights\n"
      ],
      "metadata": {
        "id": "R1Xysuv9I-Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ2Papj_jTX8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "658W9RARGEUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## count matches"
      ],
      "metadata": {
        "id": "q7fAgs5uQni_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fzy8U6_lbug"
      },
      "outputs": [],
      "source": [
        "def count_exact_matches(pred, target):\n",
        "    \"\"\"\n",
        "    Counts the number of rows in preds tensor that match exactly with each row in y tensor.\n",
        "    pred: tensor of shape (batch_size, seq_len-1)\n",
        "    y: tensor of shape (batch_size, seq_len-1)\n",
        "    \"\"\"\n",
        "    \n",
        "    count=0;\n",
        "    for i in range(pred.shape[0]):\n",
        "      flag = True\n",
        "      for j in range(pred.shape[1]):\n",
        "        if(target[i][j]!=pred[i][j]):\n",
        "          flag=False\n",
        "          break;\n",
        "         \n",
        "      if(flag):\n",
        "        count+=1;\n",
        "    \n",
        "    return count"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "n4rGh7vuQqaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp6gvWmDlWoB"
      },
      "outputs": [],
      "source": [
        "def evaluate(data,encoder, decoder,output_size,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention):\n",
        "    \n",
        "\n",
        "\n",
        "    running_loss = 0\n",
        "    correct =0\n",
        "    \n",
        "    loader = DataLoader(data, batch_size=batch_size)\n",
        "    loss_fun = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    seq_len = 0\n",
        "\n",
        "    predictions = torch.zeros(22-1, 1)\n",
        "    with torch.no_grad():\n",
        "      for j,(x,y) in enumerate(loader):\n",
        "        loss=0\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        x = x.T\n",
        "        y = y.T\n",
        "        seq_len = len(y)\n",
        "        \n",
        "        encoder_hidden=encoder.initHidden()\n",
        "        encoder_output,encoder_hidden = encoder(x,encoder_hidden)\n",
        "            \n",
        "        \n",
        "        decoder_input =y[0]\n",
        "        \n",
        "        # Handle different numbers of layers in the encoder and decoder\n",
        "        if num_layers_encoder != num_layers_decoder:\n",
        "            if num_layers_encoder < num_layers_decoder:\n",
        "                remaining_layers = num_layers_decoder - num_layers_encoder\n",
        "                # Copy all encoder hidden layers and then repeat the top layer\n",
        "                if cell_type == \"LSTM\":\n",
        "                    top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
        "                    extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
        "                    decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
        "                else:\n",
        "                    top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
        "                    extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "                    decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
        "\n",
        "            else:\n",
        "                # Slice the hidden states of the encoder to match the decoder layers\n",
        "                if cell_type == \"LSTM\":\n",
        "                    decoder_hidden = (encoder_hidden[0][-num_layers_decoder:], encoder_hidden[1][-num_layers_decoder:])\n",
        "                else :\n",
        "                    decoder_hidden = encoder_hidden[-num_layers_decoder:]\n",
        "        else:\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "        pred=torch.zeros(len(y)-1, batch_size)\n",
        "\n",
        "        for k in range(1,len(y)):\n",
        "          if attention == \"Yes\":\n",
        "              decoder_output, decoder_hidden, atten_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "          else:\n",
        "              decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
        "          max_prob, index = decoder_output.topk(1) # max_prob shape (1, batch_size, 1)\n",
        "          decoder_output = torch.squeeze(decoder_output)\n",
        "          loss += loss_fun(decoder_output, y[k].long())\n",
        "          pred[k-1]= torch.squeeze(index)\n",
        "          decoder_input = index\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        correct += count_exact_matches(pred.T,y[1:,:].T)\n",
        "        predictions = torch.cat((predictions, pred), dim=1)\n",
        "\n",
        "        \n",
        "    avg_loss = running_loss / (len(data) * seq_len)\n",
        "    print(\"correct =\", correct)\n",
        "    avg_acc = 100 * (correct / (len(data)))\n",
        "\n",
        "    if attention == \"Yes\":\n",
        "        return avg_loss, avg_acc, predictions, atten_weights\n",
        "    else:\n",
        "        return avg_loss, avg_acc, predictions\n",
        "            \n",
        "   \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SsnRWlgQmCI"
      },
      "source": [
        "# Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhDgsZG0QqPW"
      },
      "outputs": [],
      "source": [
        "def train(sweeps = True, test = False):\n",
        "\n",
        "    if sweeps == False: \n",
        "        configs = config_defaults  # use the default configuration which has the best hyperparameters\n",
        "    else:\n",
        "        wandb.init(config= config_defaults, project='DL_assign_3')   # if not test then run wandb sweeps\n",
        "        configs=wandb.config\n",
        "       \n",
        "\n",
        "    learn_rate = configs['learn_rate']\n",
        "    batch_size = configs['batch_size']\n",
        "    hidden_size = configs['hidden_size']\n",
        "    embedding_size = configs['embedding_size']\n",
        "    num_layers_encoder = configs['num_layers_encoder']\n",
        "    num_layers_decoder = configs['num_layers_decoder']\n",
        "    cell_type = configs['cell_type']\n",
        "    bidirectional = configs['bidirectional']\n",
        "    dropout = configs['dropout']\n",
        "    teach_ratio = configs['teach_ratio']\n",
        "    epochs = configs['epochs']\n",
        "    attention = configs['attention']\n",
        "\n",
        "    if sweeps:\n",
        "       wandb.run.name='hidden_'+str(hidden_size)+'_batch_'+str(batch_size)+'_embed_size_'+str(embedding_size)+'_dropout_'+str(dropout)+'_cell_'+str(cell_type)\n",
        "\n",
        "    input_len = ipLang.n_chars\n",
        "    output_len = opLang.n_chars\n",
        "    \n",
        "    encoder = EncoderRNN(input_len, hidden_size, embedding_size, \n",
        "                 num_layers_encoder, cell_type,\n",
        "                  bidirectional, dropout, batch_size)\n",
        "    \n",
        "    if attention ==\"Yes\":\n",
        "        decoder = AttentionDecoderRNN(hidden_size, output_len, embedding_size, num_layers_decoder, \n",
        "                 cell_type, dropout, batch_size, 27)\n",
        "    else:\n",
        "        decoder = DecoderRNN(hidden_size, output_len, embedding_size, num_layers_decoder, \n",
        "                 cell_type, dropout, batch_size)#dropout not used\n",
        "    \n",
        "    train_loader = DataLoader(trainData, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(valData, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n",
        "    decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n",
        "    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "    seq_len = 0\n",
        "\n",
        "    # Initialize variables for early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 5\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for i in range(epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "\n",
        "        for j,(train_x,train_y) in enumerate(train_loader):\n",
        "            train_x = train_x.to(device)\n",
        "            train_y = train_y.to(device)\n",
        "\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "\n",
        "            train_x=train_x.T\n",
        "            train_y=train_y.T\n",
        "            # print(\"train_x.shapetrain_x.shape)\n",
        "            seq_len = len(train_y)\n",
        "            encoder_hidden=encoder.initHidden()\n",
        "            # for LSTM encoder_hidden shape ((num_layers * num_directions, batch_size,hidden_size),(self.num_layers * num_directions, batch_size, hidden_size))\n",
        "            encoder_output,encoder_hidden = encoder(train_x,encoder_hidden)\n",
        "            # encoder_hidden shape (num_layers, batch_size, hidden_size)\n",
        "            \n",
        "            \n",
        "            # lets move to the decoder\n",
        "            decoder_input = train_y[0] # shape (1, batch_size)\n",
        "           \n",
        "            # Handle different numbers of layers in the encoder and decoder\n",
        "            if num_layers_encoder != num_layers_decoder:\n",
        "                if num_layers_encoder < num_layers_decoder:\n",
        "                    remaining_layers = num_layers_decoder - num_layers_encoder\n",
        "                    # Copy all encoder hidden layers and then repeat the top layer\n",
        "                    if cell_type == \"LSTM\":\n",
        "                        top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
        "                        extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
        "                        decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
        "                    else:\n",
        "                        top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
        "                        extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "                        decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
        "  \n",
        "                else:\n",
        "                    # Slice the hidden states of the encoder to match the decoder layers\n",
        "                    if cell_type == \"LSTM\":\n",
        "                        decoder_hidden = (encoder_hidden[0][-num_layers_decoder:], encoder_hidden[1][-num_layers_decoder:])\n",
        "                    else :\n",
        "                        decoder_hidden = encoder_hidden[-num_layers_decoder:]\n",
        "            else:\n",
        "                decoder_hidden = encoder_hidden\n",
        "            \n",
        "            loss = 0\n",
        "            correct = 0\n",
        "           \n",
        "            for k in range(0, len(train_y)-1):\n",
        "                \n",
        "                if attention == \"Yes\":\n",
        "                    decoder_output, decoder_hidden, atten_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "                else:\n",
        "                    decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden) # decoder_output shape (1, batch_size, output_size)\n",
        "\n",
        "                max_prob, index = decoder_output.topk(1) # max_prob shape (1, batch_size, 1)\n",
        "                index = torch.squeeze(index) # shape (batch_size)\n",
        "                decoder_output = torch.squeeze(decoder_output)\n",
        "                loss += loss_fun(decoder_output, train_y[k+1].long())\n",
        "                \n",
        "                correct += (index == train_y[k+1]).sum().item()\n",
        "\n",
        "                # Apply teacher forcing\n",
        "                use_teacher_forcing = True if random.random() < teach_ratio else False\n",
        "\n",
        "                if use_teacher_forcing:\n",
        "                    decoder_input = train_y[k+1]\n",
        "                \n",
        "                else:\n",
        "                    decoder_input = index\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            train_correct += correct\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "        \n",
        "\n",
        "        # find train loss and accuracy and print + log to wandb\n",
        "        if attention == \"Yes\":\n",
        "            _, train_accuracy,_, _ = evaluate(trainData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
        "        else:\n",
        "            _, train_accuracy,_= evaluate(trainData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
        "        \n",
        "        print(f\"epoch {i}, training loss {running_loss/(len(trainData)* seq_len)}, training accuracy {train_accuracy}\")\n",
        "        if sweeps:\n",
        "            wandb.log({\"epoch\": i, \"train_loss\": running_loss/(len(trainData)* seq_len), \"train_accuracy\": train_accuracy})\n",
        "        \n",
        "        # # find validation loss and accuracy and print + log to wandb\n",
        "        if attention == \"Yes\":\n",
        "            val_loss, val_accuracy,_, _ = evaluate(valData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
        "        else:\n",
        "            val_loss, val_accuracy,_ = evaluate(valData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
        "        \n",
        "        print(f\"epoch {i}, validation loss {val_loss}, validation accuracy {val_accuracy}\")\n",
        "        if sweeps:\n",
        "            wandb.log({\"val_loss\": val_loss, \"val_accuracy\": val_accuracy})\n",
        "\n",
        "        # Check for early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_without_improvement = 0\n",
        "            # Save the model weights\n",
        "            torch.save(encoder.state_dict(), 'best_encoder.pt')\n",
        "            torch.save(decoder.state_dict(), 'best_decoder.pt')\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(\"Early stopping triggered. No improvement in validation loss.\")\n",
        "                break\n",
        "        \n",
        "    \n",
        "    # if testing mode is on print the test accuracy \n",
        "    if test:\n",
        "        # Load the best model weights\n",
        "        encoder.load_state_dict(torch.load('best_encoder.pt'))\n",
        "        decoder.load_state_dict(torch.load('best_decoder.pt'))\n",
        "        if attention == \"Yes\":\n",
        "            _, test_accuracy, pred, atten_weights = evaluate(testData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
        "        else:\n",
        "            _, test_accuracy, pred = evaluate(testData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
        "        print(f\"test accuracy {test_accuracy}\")\n",
        "\n",
        "    if attention == \"Yes\":\n",
        "        return pred, atten_weights\n",
        "    else:\n",
        "        return pred\n",
        "           "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translating predictions to words\n"
      ],
      "metadata": {
        "id": "nvyRJWUUbR2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_prediction(input_dict , input, output_dict, pred,target):\n",
        "    \n",
        "    '''pred in shape of seq_len-1 * dataset_size\n",
        "       target in shape datasize * seq_len-1\n",
        "    '''\n",
        "    pred = pred.T # shape datasize * seq len-1\n",
        "    pred = pred[1:, :-1] # ignore last index of each row\n",
        "    input = input[:, :-1] # ignore  last index of each row\n",
        "    target = target[:, 1:-1] # ignore last index of each row\n",
        "    print(f\"pred shape {pred.shape}, input shape {input.shape}, target shape {target.shape}\")\n",
        "    predictions = [] \n",
        "    Input = [] \n",
        "    Target = []\n",
        "    for i in range(len(pred)):\n",
        "        \n",
        "        pred_word=\"\"\n",
        "        input_word=\"\"\n",
        "        target_word = \"\"\n",
        "\n",
        "        for j in range(pred.shape[1]):\n",
        "\n",
        "            # Ignore padding\n",
        "            if(target[i][j].item() != 0):\n",
        "              \n",
        "              pred_word += output_dict[pred[i][j].item()]\n",
        "              target_word += output_dict[target[i][j].item()]\n",
        "                    \n",
        "        for j in range(input.shape[1]):\n",
        "            \n",
        "               if(input[i][j].item()!=0):\n",
        "                    \n",
        "                    input_word += input_dict[input[i][j].item()]   \n",
        "\n",
        "        # Append words in respective List\n",
        "        \n",
        "        predictions.append(pred_word)\n",
        "        Input.append(input_word)         \n",
        "        Target.append(target_word)   \n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame({\"input\": Input, \"predicted\": predictions,\"Actual\":Target})\n",
        "    return df\n",
        "\n",
        "            "
      ],
      "metadata": {
        "id": "Hd3zCTnSbSaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#call train"
      ],
      "metadata": {
        "id": "8ETW0BG_Pa24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train(sweeps = False, test = True)"
      ],
      "metadata": {
        "id": "pgGp7MoGzfPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runnning sweeps for models without Attention\n",
        "\n"
      ],
      "metadata": {
        "id": "MQPGy32rnD3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sweep Config"
      ],
      "metadata": {
        "id": "z_aYZvDD1OHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "  'name': 'sweepDL',  \n",
        "  'method': 'bayes',\n",
        "  'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "  'parameters': {\n",
        "        \n",
        "        'learn_rate': {\n",
        "            'values': [0.01, 0.001, 0.001]\n",
        "        },\n",
        "        'embedding_size': {\n",
        "            'values': [32, 64, 128, 256, 512, 1024]\n",
        "        },\n",
        "        'batch_size':{\n",
        "            'values':[16, 32, 64, 128, 256]\n",
        "        },\n",
        "        'hidden_size':{\n",
        "            'values':[32, 64, 128, 256, 512, 1024]\n",
        "        },\n",
        "        'teach_ratio':{\n",
        "            'values':[0.4, 0.5, 0.6]\n",
        "        },\n",
        "        'dropout':{\n",
        "            'values':[0, 0.2, 0.4]\n",
        "        },\n",
        "        'cell_type':{\n",
        "            'values':[\"RNN\", \"LSTM\", \"GRU\"]\n",
        "        },\n",
        "        'bidirectional':{\n",
        "            'values' : [\"Yes\",\"No\"]\n",
        "        },\n",
        "        'num_layers_decoder':{\n",
        "            'values': [1,2, 3, 4]\n",
        "        },\n",
        "        'num_layers_encoder':{\n",
        "            'values': [1,2,3,4]\n",
        "        },\n",
        "        'epochs':{\n",
        "            'values': [10, 15, 20, 25, 30]\n",
        "        },\n",
        "        'attention':{\n",
        "            'values': [\"Yes\"]\n",
        "        }\n",
        "           \n",
        "    }\n",
        "}\n",
        "config_defaults={\n",
        "    'learn_rate' : 0.001,\n",
        "    'embedding_size': 32,\n",
        "    'batch_size': 256,\n",
        "    'hidden_size' : 1024,\n",
        "    'num_layers_encoder': 3,\n",
        "    'num_layers_decoder': 3,\n",
        "    'bidirectional': 'No',\n",
        "    'cell_type': \"LSTM\",\n",
        "    'teach_ratio': 0.6,\n",
        "    'dropout': 0.4,\n",
        "    'epochs': 15,\n",
        "    'attention': \"No\""
      ],
      "metadata": {
        "id": "SVv8bI-D1Q_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KxsOOpvr1oi"
      },
      "outputs": [],
      "source": [
        "# sweep_id=wandb.sweep(sweep_config, project=\"CS6910_Assignment_3\")\n",
        "# wandb.agent(sweep_id,function=train)\n",
        "# # wandb.agent(sweep_id= \"xiyggu44\",function=train, project=\"CS6910_Assignment_3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Best Model(without Attention) on Test Data \n",
        "Set default hyperparameters to the best hyperparameters got from sweeps Hyperparamer tuning"
      ],
      "metadata": {
        "id": "pKvBd5mKf0Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_defaults={\n",
        "    'learn_rate' : 0.001,\n",
        "    'embedding_size': 32,\n",
        "    'batch_size': 256,\n",
        "    'hidden_size' : 1024,\n",
        "    'num_layers_encoder': 3,\n",
        "    'num_layers_decoder': 3,\n",
        "    'bidirectional': 'No',\n",
        "    'cell_type': \"LSTM\",\n",
        "    'teach_ratio': 0.6,\n",
        "    'dropout': 0.4,\n",
        "    'epochs': 15,\n",
        "    'attention': \"No\"\n",
        "}"
      ],
      "metadata": {
        "id": "kMQvZjZl0q4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred= train(sweeps = False, test = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygtFpEvp8jFU",
        "outputId": "1a71d3be-f17f-498c-8844-3c115c411f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct = 1490\n",
            "test accuracy 36.376953125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuDZvmyMjejl",
        "outputId": "0ce1f6e0-8ffa-46e8-a470-9960abddab92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([21, 4097])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the predictions\n",
        "dataframe = translate_prediction(ipLang.index2char, testData[:][0], opLang.index2char, pred, testData[:][1])\n",
        "dataframe.to_csv(\"predictions.csv\")"
      ],
      "metadata": {
        "id": "1cgUOUdsfzUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8784a3aa-315e-476f-cced-c38ebb8434b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred shape torch.Size([4096, 20]), input shape torch.Size([4096, 26]), target shape torch.Size([4096, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2sOkc_0vmDlB",
        "outputId": "b6301168-034c-4931-c413-9e001f20d9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             input    predicted       Actual\n",
              "0          thermax      थर्मक्स      थरमैक्स\n",
              "1        sikhaaega      सिखाएगा      सिखाएगा\n",
              "2            learn         लीरर         लर्न\n",
              "3         twitters     ट्विटर्स     ट्विटर्स\n",
              "4      tirunelveli  तिरुनेवेली#  तिरुनेलवेली\n",
              "...            ...          ...          ...\n",
              "4091       saflata       सफलता#       सफ़लता\n",
              "4092        shbana        श्बान        शबाना\n",
              "4093  khaatootolaa     खातूतौला     खातूटोला\n",
              "4094    shivastava     शिवसस्तव     शिवास्तव\n",
              "4095  preranapuree  प्रेरणापुरी  प्रेरणापुरी\n",
              "\n",
              "[4096 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcefbccd-965c-4403-ac84-6bda75de68b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thermax</td>\n",
              "      <td>थर्मक्स</td>\n",
              "      <td>थरमैक्स</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sikhaaega</td>\n",
              "      <td>सिखाएगा</td>\n",
              "      <td>सिखाएगा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>learn</td>\n",
              "      <td>लीरर</td>\n",
              "      <td>लर्न</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitters</td>\n",
              "      <td>ट्विटर्स</td>\n",
              "      <td>ट्विटर्स</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tirunelveli</td>\n",
              "      <td>तिरुनेवेली#</td>\n",
              "      <td>तिरुनेलवेली</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>saflata</td>\n",
              "      <td>सफलता#</td>\n",
              "      <td>सफ़लता</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>shbana</td>\n",
              "      <td>श्बान</td>\n",
              "      <td>शबाना</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>khaatootolaa</td>\n",
              "      <td>खातूतौला</td>\n",
              "      <td>खातूटोला</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>shivastava</td>\n",
              "      <td>शिवसस्तव</td>\n",
              "      <td>शिवास्तव</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>preranapuree</td>\n",
              "      <td>प्रेरणापुरी</td>\n",
              "      <td>प्रेरणापुरी</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4096 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcefbccd-965c-4403-ac84-6bda75de68b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dcefbccd-965c-4403-ac84-6bda75de68b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dcefbccd-965c-4403-ac84-6bda75de68b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting the confusion matrix"
      ],
      "metadata": {
        "id": "FYMa5jTQRUaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CM = np.zeros((output_dict_size,output_dict_size))\n",
        "\n",
        "for i in range(target.shape[0]):\n",
        "  for j in range(target.shape[1]):\n",
        "      pred = int(predicted[i][j])\n",
        "      targ = int(target[i][j])\n",
        "      CM[pred][targ]+=1\n",
        "\n",
        "return CM\n",
        "\n",
        "  classes =[]\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "  classes.append(vocab[i])\n",
        "\n",
        "print(classes)\n",
        "# Calculate the percentages\n",
        "percentages = (cm / np.sum(cm)) * 100\n",
        "\n",
        "# Define the text for each cell\n",
        "cell_text = []\n",
        "for i in range(len(classes)):\n",
        "    row_text = []\n",
        "    for j in range(len(classes)):\n",
        "\n",
        "        txt = \"Total \"+f'{cm[i, j]}Per. ({percentages[i, j]:.3f})'\n",
        "        if(i==j):\n",
        "          txt =\"Correcty Predicted \" +classes[i]+\"\"+txt\n",
        "        if(i!=j):\n",
        "          txt =\"Predicted \" +classes[j]+\" For \"+classes[i]+\"\"+txt\n",
        "        row_text.append(txt)\n",
        "    cell_text.append(row_text)\n",
        "\n",
        "# Define the trace\n",
        "trace = go.Heatmap(z=percentages,\n",
        "                  x=classes,\n",
        "                  y=classes,\n",
        "                  colorscale='Blues',\n",
        "                  colorbar=dict(title='Percentage'),\n",
        "                  hovertemplate='%{text}%',\n",
        "                  text=cell_text,\n",
        "                  )\n",
        "\n",
        "# Define the layout\n",
        "layout = go.Layout(title='Confusion Matrix',\n",
        "                  xaxis=dict(title='Predicted Character'),\n",
        "                  yaxis=dict(title='True Character'),\n",
        "                  )\n",
        "\n",
        "# Plot the figure\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "wandb.log({'confusion_matrix': (fig)})"
      ],
      "metadata": {
        "id": "YBaJZCIBRAGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runnning sweeps for models with Attention\n"
      ],
      "metadata": {
        "id": "zfuv5FoA1wt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sweep Config"
      ],
      "metadata": {
        "id": "tsHS0PkNGHdV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwCn-Ci5xkTb"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "  'name': 'sweepDL',  \n",
        "  'method': 'bayes',\n",
        "  'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "  'parameters': {\n",
        "        \n",
        "        'learn_rate': {\n",
        "            'values': [0.01, 0.001, 0.001]\n",
        "        },\n",
        "        'embedding_size': {\n",
        "            'values': [32, 64, 128, 256, 512, 1024]\n",
        "        },\n",
        "        'batch_size':{\n",
        "            'values':[16, 32, 64, 128, 256]\n",
        "        },\n",
        "        'hidden_size':{\n",
        "            'values':[32, 64, 128, 256, 512, 1024]\n",
        "        },\n",
        "        'teach_ratio':{\n",
        "            'values':[0.4, 0.5, 0.6]\n",
        "        },\n",
        "        'dropout':{\n",
        "            'values':[0, 0.2, 0.4]\n",
        "        },\n",
        "        'cell_type':{\n",
        "            'values':[\"RNN\", \"LSTM\", \"GRU\"]\n",
        "        },\n",
        "        'bidirectional':{\n",
        "            'values' : [\"Yes\",\"No\"]\n",
        "        },\n",
        "        'num_layers_decoder':{\n",
        "            'values': [1,2, 3, 4]\n",
        "        },\n",
        "        'num_layers_encoder':{\n",
        "            'values': [1,2,3,4]\n",
        "        },\n",
        "        'epochs':{\n",
        "            'values': [10, 15, 20, 25, 30]\n",
        "        },\n",
        "        'attention':{\n",
        "            'values': [\"Yes\"]\n",
        "        }\n",
        "           \n",
        "    }\n",
        "}\n",
        "config_defaults={\n",
        "    'learn_rate' : 0.01,\n",
        "    'embedding_size': 32,\n",
        "    'batch_size': 16,\n",
        "    'hidden_size' : 128,\n",
        "    'num_layers_encoder': 2,\n",
        "    'num_layers_decoder': 3,\n",
        "    'bidirectional': 'Yes',\n",
        "    'cell_type': \"LSTM\",\n",
        "    'teach_ratio': 0.5,\n",
        "    'dropout': 0.2,\n",
        "    'epochs': 10,\n",
        "    'attention': \"Yes\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id=wandb.sweep(sweep_config, project=\"CS6910_Assignment_3\")\n",
        "wandb.agent(sweep_id,function=train)\n",
        "# wandb.agent(sweep_id= \"xiyggu44\",function=train, project=\"CS6910_Assignment_3\")"
      ],
      "metadata": {
        "id": "3ADMwinqaQVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Best Model(with Attention) on Test Data \n",
        "Set default hyperparameters to the best hyperparameters got from sweeps Hyperparamer tuning"
      ],
      "metadata": {
        "id": "W7CYNChRGuGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9MUrsXu_Rr4"
      },
      "outputs": [],
      "source": [
        "config_defaults={\n",
        "    'learn_rate' : 0.001,\n",
        "    'embedding_size': 32,\n",
        "    'batch_size': 64,\n",
        "    'hidden_size' : 1024,\n",
        "    'num_layers_encoder': 1,\n",
        "    'num_layers_decoder': 1,\n",
        "    'bidirectional': 'Yes',\n",
        "    'cell_type': \"LSTM\",\n",
        "    'teach_ratio': 0.5,\n",
        "    'dropout': 0.4,\n",
        "    'epochs': 20,\n",
        "    'attention': \"Yes\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred, atten_weights = train(sweeps = False, test = True)"
      ],
      "metadata": {
        "id": "u7XAB4Q5Hpxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f778c2e5-41b7-44c9-f250-cd40d923fef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct = 5814\n",
            "epoch 0, training loss 0.957991349588741, training accuracy 11.35546875\n",
            "correct = 601\n",
            "epoch 0, validation loss 0.4595895152200352, validation accuracy 14.6728515625\n",
            "correct = 14585\n",
            "epoch 1, training loss 0.3925387893752618, training accuracy 28.486328125\n",
            "correct = 1283\n",
            "epoch 1, validation loss 0.35384030775590375, validation accuracy 31.3232421875\n",
            "correct = 18964\n",
            "epoch 2, training loss 0.2797692700814117, training accuracy 37.0390625\n",
            "correct = 1491\n",
            "epoch 2, validation loss 0.32936020635745744, validation accuracy 36.4013671875\n",
            "correct = 22476\n",
            "epoch 3, training loss 0.2354164336350831, training accuracy 43.8984375\n",
            "correct = 1596\n",
            "epoch 3, validation loss 0.3346057998185808, validation accuracy 38.96484375\n",
            "correct = 25304\n",
            "epoch 4, training loss 0.20472266645594075, training accuracy 49.421875\n",
            "correct = 1667\n",
            "epoch 4, validation loss 0.3202064755288037, validation accuracy 40.6982421875\n",
            "correct = 27824\n",
            "epoch 5, training loss 0.17851644559340044, training accuracy 54.34375\n",
            "correct = 1734\n",
            "epoch 5, validation loss 0.32552727819843724, validation accuracy 42.333984375\n",
            "correct = 30498\n",
            "epoch 6, training loss 0.1633032681996172, training accuracy 59.56640625\n",
            "correct = 1758\n",
            "epoch 6, validation loss 0.335581511259079, validation accuracy 42.919921875\n",
            "correct = 32648\n",
            "epoch 7, training loss 0.14449133916334672, training accuracy 63.765625\n",
            "correct = 1821\n",
            "epoch 7, validation loss 0.32749663496559317, validation accuracy 44.4580078125\n",
            "correct = 35748\n",
            "epoch 8, training loss 0.1273884732479399, training accuracy 69.8203125\n",
            "correct = 1766\n",
            "epoch 8, validation loss 0.3376287784088742, validation accuracy 43.115234375\n",
            "correct = 37914\n",
            "epoch 9, training loss 0.11190265557305379, training accuracy 74.05078125\n",
            "correct = 1774\n",
            "epoch 9, validation loss 0.3441204188222235, validation accuracy 43.310546875\n",
            "Early stopping triggered. No improvement in validation loss.\n",
            "correct = 1622\n",
            "test accuracy 39.599609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the predictions\n",
        "dataframe = translate_prediction(ipLang.index2char, testData[:][0], opLang.index2char, pred, testData[:][1])\n",
        "dataframe.to_csv(\"predictions.csv\")"
      ],
      "metadata": {
        "id": "pHPV33NAYPsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b232d70a-7341-4055-9e2d-a03d93421319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred shape torch.Size([4096, 20]), input shape torch.Size([4096, 26]), target shape torch.Size([4096, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "id": "_g9mqSbTPwPb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b66dae35-0314-48ec-9a8f-ee1e9064b5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             input    predicted       Actual\n",
              "0          thermax      थर्मैक्      थरमैक्स\n",
              "1        sikhaaega      सिखाएगा      सिखाएगा\n",
              "2            learn         लीर्         लर्न\n",
              "3         twitters     टविटर्स#     ट्विटर्स\n",
              "4      tirunelveli  तिरुनेलवेली  तिरुनेलवेली\n",
              "...            ...          ...          ...\n",
              "4091       saflata       सफलाता       सफ़लता\n",
              "4092        shbana        शबाना        शबाना\n",
              "4093  khaatootolaa     खातूतोला     खातूटोला\n",
              "4094    shivastava     शिवास्तव     शिवास्तव\n",
              "4095  preranapuree  प्रेराणपुरी  प्रेरणापुरी\n",
              "\n",
              "[4096 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1c6b29b-badd-46d0-943e-50fc9f8c0bbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thermax</td>\n",
              "      <td>थर्मैक्</td>\n",
              "      <td>थरमैक्स</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sikhaaega</td>\n",
              "      <td>सिखाएगा</td>\n",
              "      <td>सिखाएगा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>learn</td>\n",
              "      <td>लीर्</td>\n",
              "      <td>लर्न</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitters</td>\n",
              "      <td>टविटर्स#</td>\n",
              "      <td>ट्विटर्स</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tirunelveli</td>\n",
              "      <td>तिरुनेलवेली</td>\n",
              "      <td>तिरुनेलवेली</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>saflata</td>\n",
              "      <td>सफलाता</td>\n",
              "      <td>सफ़लता</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>shbana</td>\n",
              "      <td>शबाना</td>\n",
              "      <td>शबाना</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>khaatootolaa</td>\n",
              "      <td>खातूतोला</td>\n",
              "      <td>खातूटोला</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>shivastava</td>\n",
              "      <td>शिवास्तव</td>\n",
              "      <td>शिवास्तव</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>preranapuree</td>\n",
              "      <td>प्रेराणपुरी</td>\n",
              "      <td>प्रेरणापुरी</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4096 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1c6b29b-badd-46d0-943e-50fc9f8c0bbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1c6b29b-badd-46d0-943e-50fc9f8c0bbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1c6b29b-badd-46d0-943e-50fc9f8c0bbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atten_weights.shape"
      ],
      "metadata": {
        "id": "EXCspYKeGSps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the Attention HeatMaps"
      ],
      "metadata": {
        "id": "LDP4KvWdFnIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "configs = config_defaults  # use the default configuration which has the best hyperparameters\n",
        "learn_rate = configs['learn_rate']\n",
        "batch_size = configs['batch_size']\n",
        "hidden_size = configs['hidden_size']\n",
        "embedding_size = configs['embedding_size']\n",
        "num_layers_encoder = configs['num_layers_encoder']\n",
        "num_layers_decoder = configs['num_layers_decoder']\n",
        "cell_type = configs['cell_type']\n",
        "bidirectional = configs['bidirectional']\n",
        "dropout = configs['dropout']\n",
        "teach_ratio = configs['teach_ratio']\n",
        "epochs = configs['epochs']\n",
        "attention = configs['attention']\n",
        "\n",
        "input_len = ipLang.n_chars\n",
        "output_len = opLang.n_chars\n",
        "\n",
        "encoder = EncoderRNN(input_len, hidden_size, embedding_size, \n",
        "              num_layers_encoder, cell_type,\n",
        "              bidirectional, dropout, batch_size)\n",
        "\n",
        "if attention ==\"Yes\":\n",
        "    decoder = AttentionDecoderRNN(hidden_size, output_len, embedding_size, num_layers_decoder, \n",
        "              cell_type, dropout, batch_size, 27)\n",
        "else:\n",
        "    decoder = DecoderRNN(hidden_size, output_len, embedding_size, num_layers_decoder, \n",
        "              cell_type, dropout, batch_size)#dropout not used\n",
        "\n",
        "encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n",
        "decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n",
        "loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "# Load the best model weights\n",
        "encoder.load_state_dict(torch.load('best_encoder.pt'))\n",
        "decoder.load_state_dict(torch.load('best_decoder.pt'))\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "x = testData[0][:10, :].to(device)\n",
        "y = y[0][:10, :].to(device)\n",
        "x = x.T\n",
        "y = y.T\n",
        "seq_len = len(y)\n",
        "        \n",
        "encoder_hidden=encoder.initHidden()\n",
        "encoder_output,encoder_hidden = encoder(x,encoder_hidden)\n",
        "                 \n",
        "decoder_input =y[0]\n",
        "\n",
        "# Handle different numbers of layers in the encoder and decoder\n",
        "if num_layers_encoder != num_layers_decoder:\n",
        "    if num_layers_encoder < num_layers_decoder:\n",
        "        remaining_layers = num_layers_decoder - num_layers_encoder\n",
        "        # Copy all encoder hidden layers and then repeat the top layer\n",
        "        if cell_type == \"LSTM\":\n",
        "            top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
        "            extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
        "            decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
        "        else:\n",
        "            top_layer_hidden = encoder_hidden[-1].unsqueeze(0) \n",
        "            extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "            decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
        "\n",
        "    else:\n",
        "        # Slice the hidden states of the encoder to match the decoder layers\n",
        "        if cell_type == \"LSTM\":\n",
        "            decoder_hidden = (encoder_hidden[0][-num_layers_decoder:], encoder_hidden[1][-num_layers_decoder:])\n",
        "        else :\n",
        "            decoder_hidden = encoder_hidden[-num_layers_decoder:]\n",
        "else:\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "pred=torch.zeros(len(y)-1, 10)\n",
        "\n",
        "for k in range(1,len(y)):\n",
        "  if attention == \"Yes\":\n",
        "      decoder_output, decoder_hidden, atten_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "  else:\n",
        "      decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
        "max_prob, index = decoder_output.topk(1) # max_prob shape (1, batch_size, 1)\n",
        "decoder_output = torch.squeeze(decoder_output)\n",
        "pred[k-1]= torch.squeeze(index)\n",
        "decoder_input = index\n",
        "\n",
        "# Normalize the attention weights across the input sequence axis\n",
        "attention_weights = atten_weights / np.sum(attention_weights, axis=2, keepdims=True)\n",
        "print(attention_weights.shape)\n",
        "\n",
        "attention_weights_fixed = np.nan_to_num(attention_weights, nan=0.0000001)\n",
        "\n",
        "# Create a 3x3 grid of subplots for heatmaps\n",
        "fig = make_subplots(rows=4, cols=4)\n",
        "\n",
        "# Add heatmaps to the grid\n",
        "for i in range(batch_size):\n",
        "    heatmap = attention_weights[i]\n",
        "    \n",
        "    x_label , y_label = [] , []\n",
        "\n",
        "    for k in range(X.shape[1]):\n",
        "      char = data.input_lang.index2char[(X[i][k]).item()]\n",
        "      x_label.append(char)\n",
        "    \n",
        "    for k in range(Y.shape[1]):\n",
        "      char = data.output_lang.index2char[(Y[i][k]).item()]\n",
        "      y_label.append(char)\n",
        "    # Create a heatmap trace\n",
        "    heatmap_trace = go.Heatmap(z=heatmap,\n",
        "                              x=y_label,\n",
        "                              y=x_label,\n",
        "                              colorscale='hot',\n",
        "                              reversescale=True,\n",
        "                              showscale=False)\n",
        "\n",
        "    # Add the heatmap trace to the subplot\n",
        "    row = (i // 4) + 1\n",
        "    col = (i % 4) + 1\n",
        "    fig.add_trace(heatmap_trace, row=row, col=col)\n",
        "\n",
        "    # Set subplot titles\n",
        "    # Set subplot titles\n",
        "\n",
        "    fig.update_xaxes(title_text=\"Output Sequence\", row=row, col=col)\n",
        "    fig.update_yaxes(title_text=\"Input Sequnece\", row=row, col=col)\n",
        "\n",
        "    # Update subplot titles\n",
        "    fig.update_layout(title=f\"Attention Heatmap Grid\", height=800, width=800)\n",
        "\n",
        "# Show the grid of heatmaps\n",
        "wandb.log({\"heatmap \":fig})\n",
        "          "
      ],
      "metadata": {
        "id": "4WfJEdcgFmiI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "658W9RARGEUf"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}